version: "3.8"

services:
  lol-predict-ml-pipeline:
    image: lol-predict-ml-pipeline:latest
    entrypoint: /bin/bash
    tty: true
    stdin_open: true # Simule un terminal
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.12.1
    container_name: mlflow_server
    ports:
      - "5000:5000"
    volumes:
      - ./mlflow/mlruns:/mlflow/mlruns
    command: >
      mlflow server 
      --backend-store-uri sqlite:///mlflow.db 
      --default-artifact-root /mlflow/mlruns 
      --host 0.0.0.0 
      --port 5000
    working_dir: /mlflow/mlruns
